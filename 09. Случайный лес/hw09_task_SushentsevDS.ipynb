{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "hw09_task_SushentsevDS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PjQglGj4q54"
      },
      "source": [
        "# Случайные леса\n",
        "__Суммарное количество баллов: 10__\n",
        "\n",
        "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
        "\n",
        "__Тема письма: `[ML][MS][HW09] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
        "\n",
        "В этом задании вам предстоит реализовать ансамбль деревьев решений, известный как случайный лес, применить его к публичным данным пользователей социальной сети Вконтакте, и сравнить его эффективность с ансамблем, предоставляемым библиотекой CatBoost.\n",
        "\n",
        "В результате мы сможем определить, какие подписки пользователей больше всего влияют на определение возраста и пола человека. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6sNKMLZqSDi"
      },
      "source": [
        "!pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH5PiGz04q5-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import copy\n",
        "from scipy.stats import mode \n",
        "from catboost import CatBoostClassifier"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQUJHTjS4q5-"
      },
      "source": [
        "def gini(x):\n",
        "    _, counts = np.unique(x, return_counts=True)\n",
        "    proba = counts / len(x)\n",
        "    return np.sum(proba * (1 - proba))\n",
        "    \n",
        "def entropy(x):\n",
        "    _, counts = np.unique(x, return_counts=True)\n",
        "    proba = counts / len(x)\n",
        "    return -np.sum(proba * np.log2(proba))\n",
        "\n",
        "def gain(left_y, right_y, criterion):\n",
        "    y = np.concatenate((left_y, right_y))\n",
        "    return criterion(y) - (criterion(left_y) * len(left_y) + criterion(right_y) * len(right_y)) / len(y)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfxycK0Q4q5_"
      },
      "source": [
        "### Задание 1 (2 балла)\n",
        "Random Forest состоит из деревьев решений. Каждое такое дерево строится на одной из выборок, полученных при помощи bagging. Элементы, которые не вошли в новую обучающую выборку, образуют out-of-bag выборку. Кроме того, в каждом узле дерева мы случайным образом выбираем набор из `max_features` и ищем признак для предиката разбиения только в этом наборе.\n",
        "\n",
        "Сегодня мы будем работать только с бинарными признаками, поэтому нет необходимости выбирать значение признака для разбиения.\n",
        "\n",
        "#### Методы\n",
        "`predict(X)` - возвращает предсказанные метки для элементов выборки `X`\n",
        "\n",
        "#### Параметры конструктора\n",
        "`X, y` - обучающая выборка и соответствующие ей метки классов. Из нее нужно получить выборку для построения дерева при помощи bagging. Out-of-bag выборку нужно запомнить, она понадобится потом.\n",
        "\n",
        "`criterion=\"gini\"` - задает критерий, который будет использоваться при построении дерева. Возможные значения: `\"gini\"`, `\"entropy\"`.\n",
        "\n",
        "`max_depth=None` - ограничение глубины дерева. Если `None` - глубина не ограничена\n",
        "\n",
        "`min_samples_leaf=1` - минимальное количество элементов в каждом листе дерева.\n",
        "\n",
        "`max_features=\"auto\"` - количество признаков, которые могут использоваться в узле. Если `\"auto\"` - равно `sqrt(X.shape[1])`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qte6EpC0vns"
      },
      "source": [
        "class DecisionTreeLeaf:\n",
        "    def __init__(self, y):\n",
        "        self.y = mode(y)[0].squeeze()\n",
        "\n",
        "\n",
        "class DecisionTreeNode:\n",
        "    def __init__(self, split_dim, left, right):\n",
        "        self.split_dim = split_dim\n",
        "        self.left = left\n",
        "        self.right = right"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8smLW2V_4q5_"
      },
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, X, y, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=\"auto\"):\n",
        "        self.X, self.y = X, y\n",
        "        self.train_indices = np.random.choice(len(X), size=len(X), replace=True)\n",
        "        self.oob_indices = set(np.setdiff1d(np.arange(len(X)), self.train_indices))\n",
        "        self.criterion = gini if criterion == \"gini\" else entropy\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.max_features = round(np.sqrt(X.shape[1])) if max_features == \"auto\" else max_features\n",
        "        self.root, self.depth = self._build_tree(self.train_indices, 0)\n",
        "  \n",
        "    def _build_tree(self, indices, depth):\n",
        "        if (self.max_depth is not None) and (depth >= self.max_depth):\n",
        "            return DecisionTreeLeaf(self.y[indices]), depth\n",
        "\n",
        "        partition = self._get_partition(indices)\n",
        "\n",
        "        if partition is None:\n",
        "            return DecisionTreeLeaf(self.y[indices]), depth\n",
        "\n",
        "        left_indices, right_indices, split_dim = partition\n",
        "        left_tree, left_depth = self._build_tree(left_indices, depth + 1)\n",
        "        right_tree, right_depth = self._build_tree(right_indices, depth + 1)\n",
        "        return DecisionTreeNode(split_dim, left_tree, right_tree), max(left_depth, right_depth)\n",
        "\n",
        "    def _get_partition(self, indices):\n",
        "        X, y = self.X[indices], self.y[indices]\n",
        "        max_gain = float('-inf')\n",
        "        split_dim = left_indices = right_indices = None\n",
        "        features = np.random.choice(X.shape[1], size=self.max_features, replace=False)\n",
        "\n",
        "        for feature in features:\n",
        "            left, right = indices[X[:, feature] == 0], indices[X[:, feature] == 1]\n",
        "\n",
        "            if (len(left) < self.min_samples_leaf) or (len(right) < self.min_samples_leaf):\n",
        "                continue\n",
        "\n",
        "            gain_ = gain(self.y[left], self.y[right], self.criterion)\n",
        "            \n",
        "            if gain_ > max_gain:\n",
        "                max_gain = gain_\n",
        "                split_dim = feature\n",
        "                left_indices, right_indices = left, right\n",
        "        \n",
        "        return None if split_dim is None else (left_indices, right_indices, split_dim)\n",
        "        \n",
        "    def predict(self, X):\n",
        "        if X.ndim == 1:\n",
        "            X = X.reshape(1, -1)\n",
        "\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            node = self.root \n",
        "\n",
        "            while not isinstance(node, DecisionTreeLeaf):\n",
        "                node = node.left if x[node.split_dim] == 0 else node.right\n",
        "            predictions.append(node.y)\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oijgwLt4q6A"
      },
      "source": [
        "### Задание 2 (2 балла)\n",
        "Теперь реализуем сам Random Forest. Идея очень простая: строим `n` деревьев, а затем берем модальное предсказание.\n",
        "\n",
        "#### Параметры конструктора\n",
        "`n_estimators` - количество используемых для предсказания деревьев.\n",
        "\n",
        "Остальное - параметры деревьев.\n",
        "\n",
        "#### Методы\n",
        "`fit(X, y)` - строит `n_estimators` деревьев по выборке `X`.\n",
        "\n",
        "`predict(X)` - для каждого элемента выборки `X` возвращает самый частый класс, который предсказывают для него деревья."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APIy88YW4q6A"
      },
      "source": [
        "class RandomForestClassifier:\n",
        "    def __init__(self, criterion=\"gini\", max_depth=None, min_samples_leaf=1, max_features=\"auto\", n_estimators=10):\n",
        "        self.criterion = criterion\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.max_features = max_features\n",
        "        self.n_estimators = n_estimators\n",
        "        self.X = self.y = self.estimators = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.X, self.y = X, y\n",
        "        self.estimators = []\n",
        "        \n",
        "        for _ in range(self.n_estimators):\n",
        "            tree = DecisionTree(X, y, self.criterion, self.max_depth, \n",
        "                                self.min_samples_leaf, self.max_features)\n",
        "            self.estimators.append(tree)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        predictions = self.estimators[0].predict(X)\n",
        "\n",
        "        for estimator in self.estimators[1:]:\n",
        "            predictions = np.vstack((predictions, estimator.predict(X)))\n",
        "        \n",
        "        return mode(predictions, axis=0)[0].squeeze()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i80pffMn4q6A"
      },
      "source": [
        "### Задание 3 (2 балла)\n",
        "Часто хочется понимать, насколько большую роль играет тот или иной признак для предсказания класса объекта. Есть различные способы посчитать его важность. Один из простых способов сделать это для Random Forest - посчитать out-of-bag ошибку предсказания `err_oob`, а затем перемешать значения признака `j` и посчитать ее (`err_oob_j`) еще раз. Оценкой важности признака `j` для одного дерева будет разность `err_oob_j - err_oob`, важность для всего леса считается как среднее значение важности по деревьям.\n",
        "\n",
        "Реализуйте функцию `feature_importance`, которая принимает на вход Random Forest и возвращает массив, в котором содержится важность для каждого признака."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEmVG1Fl4q6B"
      },
      "source": [
        "def oob_error(rfc, X, y):\n",
        "    true = size = 0\n",
        "\n",
        "    for index, x in enumerate(X):\n",
        "        pred = [estimator.predict(x)[0] for estimator in rfc.estimators \n",
        "                if index in estimator.oob_indices]\n",
        "\n",
        "        if len(pred) > 0:\n",
        "            size += 1\n",
        "            pred = mode(pred)[0][0]\n",
        "            true += (pred == y[index])\n",
        "\n",
        "    return 1 - true / size\n",
        "\n",
        "\n",
        "def feature_importance(rfc):\n",
        "    importance = []\n",
        "    err_oob = oob_error(rfc, rfc.X, rfc.y)\n",
        "\n",
        "    for i in range(rfc.X.shape[1]):\n",
        "        X_new = rfc.X.copy()\n",
        "        np.random.shuffle(X_new[:, i])\n",
        "        err_oob_i = oob_error(rfc, X_new, rfc.y)\n",
        "        importance.append(err_oob_i - err_oob)\n",
        "\n",
        "    return importance\n",
        "\n",
        "\n",
        "def most_important_features(importance, names, k=20):\n",
        "    # Выводит названия k самых важных признаков\n",
        "    indices = np.argsort(importance)[::-1][:k]\n",
        "    return np.array(names)[indices]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JooN_YKm4q6B"
      },
      "source": [
        "Наконец, пришло время протестировать наше дерево на простом синтетическом наборе данных. В результате точность должна быть примерно равна `1.0`, наибольшее значение важности должно быть у признака с индексом `4`, признаки с индексами `2` и `3`  должны быть одинаково важны, а остальные признаки - не важны совсем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gqYMp994q6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e0683b7-10be-4483-f911-5e8ebec0601e"
      },
      "source": [
        "def synthetic_dataset(size):\n",
        "    X = [(np.random.randint(0, 2), np.random.randint(0, 2), i % 6 == 3, \n",
        "          i % 6 == 0, i % 3 == 2, np.random.randint(0, 2)) for i in range(size)]\n",
        "    y = [i % 3 for i in range(size)]\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X, y = synthetic_dataset(1000)\n",
        "rfc = RandomForestClassifier(n_estimators=100)\n",
        "rfc.fit(X, y)\n",
        "print(\"Accuracy:\", np.mean(rfc.predict(X) == y))\n",
        "print(\"Importance:\", feature_importance(rfc))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n",
            "Importance: [0.0, 0.0, 0.19899999999999995, 0.20199999999999996, 0.45699999999999996, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRtGOs164q6C"
      },
      "source": [
        "### Задание 4 (1 балл)\n",
        "Теперь поработаем с реальными данными.\n",
        "\n",
        "Выборка состоит из публичных анонимизированных данных пользователей социальной сети Вконтакте. Первые два столбца отражают возрастную группу (`zoomer`, `doomer` и `boomer`) и пол (`female`, `male`). Все остальные столбцы являются бинарными признаками, каждый из них определяет, подписан ли пользователь на определенную группу/публичную страницу или нет.\\\n",
        "\\\n",
        "Необходимо обучить два классификатора, один из которых определяет возрастную группу, а второй - пол.\\\n",
        "\\\n",
        "Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются. Лес должен строиться за какое-то разумное время."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HruobK-q4q6C"
      },
      "source": [
        "def read_dataset(path):\n",
        "    dataframe = pandas.read_csv(path, header=0)\n",
        "    dataset = dataframe.values.tolist()\n",
        "    random.shuffle(dataset)\n",
        "    y_age = [row[0] for row in dataset]\n",
        "    y_sex = [row[1] for row in dataset]\n",
        "    X = [row[2:] for row in dataset]\n",
        "    \n",
        "    return np.array(X), np.array(y_age), np.array(y_sex), list(dataframe.columns)[2:]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0QXWr3b4q6C"
      },
      "source": [
        "X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n",
        "X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0y8J97m4q6C"
      },
      "source": [
        "#### Возраст"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLJykJZH4q6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c466a3-cd68-4104-c6b4-ab46fe3427d7"
      },
      "source": [
        "%%time\n",
        "rfc = RandomForestClassifier(n_estimators=10)\n",
        "\n",
        "rfc.fit(X_train, y_age_train)\n",
        "print(\"Accuracy:\", np.mean(rfc.predict(X_test) == y_age_test))\n",
        "print(\"Most important features:\")\n",
        "for i, name in enumerate(most_important_features(feature_importance(rfc), features, 20)):\n",
        "    print(str(i+1) + \".\", name)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7490542244640606\n",
            "Most important features:\n",
            "1. ovsyanochan\n",
            "2. mudakoff\n",
            "3. 4ch\n",
            "4. rhymes\n",
            "5. styd.pozor\n",
            "6. dayvinchik\n",
            "7. ohhluul\n",
            "8. rapnewrap\n",
            "9. pravdashowtop\n",
            "10. i_d_t\n",
            "11. pixel_stickers\n",
            "12. pozor\n",
            "13. reflexia_our_feelings\n",
            "14. bot_maxim\n",
            "15. leprum\n",
            "16. thesmolny\n",
            "17. iwantyou\n",
            "18. tumblr_vacuum\n",
            "19. borsch\n",
            "20. i_des\n",
            "CPU times: user 4min 27s, sys: 368 ms, total: 4min 27s\n",
            "Wall time: 4min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgNpaAKH4q6D"
      },
      "source": [
        "#### Пол"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-zne5-R4q6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e402e7-a8b5-4878-de4c-7b44c7538657"
      },
      "source": [
        "%%time\n",
        "rfc = RandomForestClassifier(n_estimators=10)\n",
        "rfc.fit(X_train, y_sex_train)\n",
        "print(\"Accuracy:\", np.mean(rfc.predict(X_test) == y_sex_test))\n",
        "print(\"Most important features:\")\n",
        "for i, name in enumerate(most_important_features(feature_importance(rfc), features, 20)):\n",
        "    print(str(i+1) + \".\", name)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8524590163934426\n",
            "Most important features:\n",
            "1. 40kg\n",
            "2. zerofat\n",
            "3. mudakoff\n",
            "4. modnailru\n",
            "5. girlmeme\n",
            "6. 9o_6o_9o\n",
            "7. femalemem\n",
            "8. recipes40kg\n",
            "9. woman.blog\n",
            "10. i_d_t\n",
            "11. thesmolny\n",
            "12. cook_good\n",
            "13. be.beauty\n",
            "14. igm\n",
            "15. be.women\n",
            "16. bon\n",
            "17. 4ch\n",
            "18. reflexia_our_feelings\n",
            "19. beauty\n",
            "20. soverwenstvo.decora\n",
            "CPU times: user 4min 23s, sys: 262 ms, total: 4min 23s\n",
            "Wall time: 4min 23s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxeTQylQ4q6D"
      },
      "source": [
        "### CatBoost\n",
        "В качестве альтернативы попробуем CatBoost. \n",
        "\n",
        "Установить его можно просто с помощью `pip install catboost`. Туториалы можно найти, например, [здесь](https://catboost.ai/docs/concepts/python-usages-examples.html#multiclassification) и [здесь](https://github.com/catboost/tutorials/blob/master/python_tutorial.ipynb). Главное - не забудьте использовать `loss_function='MultiClass'`.\\\n",
        "\\\n",
        "Сначала протестируйте CatBoost на синтетических данных. Выведите точность и важность признаков."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOqVkEnd4q6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43840a2-aaa9-457d-f101-db486bad9efa"
      },
      "source": [
        "X, y = synthetic_dataset(1000)\n",
        "model = CatBoostClassifier(iterations=10, \n",
        "                           learning_rate=1, \n",
        "                           depth=2, \n",
        "                           loss_function='MultiClass',\n",
        "                           random_seed=0)\n",
        "model.fit(X, y, verbose=False)\n",
        "print(\"Accuracy:\", np.mean(model.predict(X).squeeze() == y))\n",
        "print(\"Importance:\", model.get_feature_importance())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n",
            "Importance: [ 0.          0.         22.24583462 28.33697139 49.41719399  0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcLRsSNG4q6E"
      },
      "source": [
        "### Задание 5 (3 балла)\n",
        "Попробуем применить один из используемых на практике алгоритмов. В этом нам поможет CatBoost. Также, как и реализованный ними RandomForest, применим его для определения пола и возраста пользователей сети Вконтакте, выведите названия наиболее важных признаков так же, как в задании 3.\\\n",
        "\\\n",
        "Эксперименты с множеством используемых признаков и подбор гиперпараметров приветствуются."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJGrQcO-4q6E"
      },
      "source": [
        "X, y_age, y_sex, features = read_dataset(\"vk.csv\")\n",
        "X_train, X_test, y_age_train, y_age_test, y_sex_train, y_sex_test = train_test_split(X, y_age, y_sex, train_size=0.9)\n",
        "X_train, X_eval, y_age_train, y_age_eval, y_sex_train, y_sex_eval = train_test_split(X_train, y_age_train, y_sex_train, train_size=0.8)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA5f_8eC4q6E"
      },
      "source": [
        "#### Возраст"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBJaTAbgF2Er",
        "outputId": "f712b10b-bf2c-4d9c-a696-0bb1b169660d"
      },
      "source": [
        "%%time\n",
        "model = CatBoostClassifier(iterations=100, loss_function='MultiClass', random_seed=0)\n",
        "grid = {'learning_rate': [0.01, 0.1, 1],\n",
        "        'depth': [4, 6, 8, 10],\n",
        "        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
        "\n",
        "grid_search_result = model.grid_search(grid, \n",
        "                                       X=X_train, \n",
        "                                       y=y_age_train, \n",
        "                                       partition_random_seed=0,\n",
        "                                       verbose=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 26min 44s, sys: 10.5 s, total: 26min 54s\n",
            "Wall time: 13min 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndkbTo83OyJf",
        "outputId": "a4bd3576-e4bd-4f68-83eb-c56e88757adc"
      },
      "source": [
        "grid_search_result['params']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'depth': 10, 'l2_leaf_reg': 1, 'learning_rate': 0.1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSeUpxPj4q6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced28538-b579-453e-b4bd-e1f86d6da98b"
      },
      "source": [
        "model = CatBoostClassifier(iterations=100, \n",
        "                           **grid_search_result['params'],\n",
        "                           loss_function='MultiClass',\n",
        "                           random_seed=0)\n",
        "model.fit(X_train, y_age_train, verbose=False)\n",
        "print(\"Accuracy:\", np.mean(model.predict(X_test).squeeze() == y_age_test))\n",
        "print(\"Most important features:\")\n",
        "for i, name in enumerate(most_important_features(model.get_feature_importance(), features, 10)):\n",
        "    print(str(i+1) + \".\", name)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.725094577553594\n",
            "Most important features:\n",
            "1. ovsyanochan\n",
            "2. mudakoff\n",
            "3. styd.pozor\n",
            "4. 4ch\n",
            "5. rhymes\n",
            "6. dayvinchik\n",
            "7. rapnewrap\n",
            "8. leprum\n",
            "9. iwantyou\n",
            "10. xfilm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfYSptm74q6E"
      },
      "source": [
        "#### Пол"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2tXKzuCOmdw"
      },
      "source": [
        "%%time\n",
        "model = CatBoostClassifier(iterations=100, loss_function='MultiClass', random_seed=0)\n",
        "grid = {'learning_rate': [0.01, 0.1, 1],\n",
        "        'depth': [4, 6, 8, 10],\n",
        "        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
        "\n",
        "grid_search_result = model.grid_search(grid, \n",
        "                                       X=X_train, \n",
        "                                       y=y_sex_train, \n",
        "                                       partition_random_seed=0,\n",
        "                                       verbose=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rKa-f6F4q6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538a2303-efa5-4979-a04a-4d627808b41a"
      },
      "source": [
        "model = CatBoostClassifier(iterations=100, \n",
        "                           **grid_search_result['params'],\n",
        "                           loss_function='MultiClass',\n",
        "                           random_seed=0)\n",
        "model.fit(X_train, y_sex_train, verbose=False)\n",
        "print(\"Accuracy:\", np.mean(model.predict(X_test).squeeze() == y_sex_test))\n",
        "print(\"Most important features:\")\n",
        "for i, name in enumerate(most_important_features(model.get_feature_importance(), features, 10)):\n",
        "    print(str(i+1) + \".\", name)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8474148802017655\n",
            "Most important features:\n",
            "1. 40kg\n",
            "2. mudakoff\n",
            "3. igm\n",
            "4. girlmeme\n",
            "5. zerofat\n",
            "6. modnailru\n",
            "7. 9o_6o_9o\n",
            "8. academyofman\n",
            "9. be.beauty\n",
            "10. thesmolny\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lV182eM4Rqq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}